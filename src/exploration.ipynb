{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "from train_test import train, test\n",
    "import warnings\n",
    "import json\n",
    "from arg_parser import init_parser\n",
    "from setproctitle import setproctitle as ptitle\n",
    "from enviroment import ARC_Env\n",
    "import gymnasium as gym\n",
    "from action_space import ARCActionSpace\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def init_parser(alg):\n",
    "\n",
    "    if alg == 'WOLP_DDPG':\n",
    "        parser = argparse.ArgumentParser(description='WOLP_DDPG')\n",
    "        parser.add_argument('--env', default='ARC', metavar='ENV', help='environment to train on')\n",
    "        parser.add_argument('--gamma', type=float, default=0.99, metavar='G', help='discount factor for rewards (default: 0.99)')\n",
    "        parser.add_argument('--max-episode-length', type=int, default=50, metavar='M', help='maximum length of an episode (default: 1440)') #NOTE: changed from 1440 to 5\n",
    "        parser.add_argument('--load', default=False, metavar='L', help='load a trained model')\n",
    "        parser.add_argument('--load-model-dir', default='ARC-run975', metavar='LMD', help='folder to load trained models from')\n",
    "        parser.add_argument('--gpu-ids', type=int, default=[1], nargs='+', help='GPUs to use [-1 CPU only]')\n",
    "        parser.add_argument('--gpu-nums', type=int, default=8, help='#GPUs to use (default: 1)')\n",
    "        parser.add_argument('--max-episode', type=int, default=20000, help='maximum #episode.')\n",
    "        parser.add_argument('--test-episode', type=int, default=20, help='maximum testing #episode.')\n",
    "        parser.add_argument('--max-actions', default=1e8, type=int, help='# max actions')\n",
    "        parser.add_argument('--id', default='0', type=str, help='experiment id')\n",
    "        parser.add_argument('--mode', default='train', type=str, help='support option: train/test')\n",
    "        parser.add_argument('--hidden1', default=256, type=int, help='hidden num of first fully connect layer')\n",
    "        parser.add_argument('--hidden2', default=128, type=int, help='hidden num of second fully connect layer')\n",
    "        parser.add_argument('--c-lr', default=1e-3, type=float, help='critic net learning rate')\n",
    "        parser.add_argument('--p-lr', default=1e-3, type=float, help='policy net learning rate (only for DDPG)')\n",
    "        parser.add_argument('--warmup', default=500, type=int, help='time without training but only filling the replay memory')\n",
    "        parser.add_argument('--bsize', default=32, type=int, help='minibatch size')\n",
    "        parser.add_argument('--rmsize', default=100000, type=int, help='memory size')\n",
    "        parser.add_argument('--window_length', default=1, type=int, help='')\n",
    "        parser.add_argument('--tau-update', default=0.0005, type=float, help='moving average for target network')\n",
    "        parser.add_argument('--ou_theta', default=0.5, type=float, help='noise theta')\n",
    "        parser.add_argument('--ou_sigma', default=0.2, type=float, help='noise sigma')\n",
    "        parser.add_argument('--ou_mu', default=0.0, type=float, help='noise mu')\n",
    "        parser.add_argument('--init_w', default=0.003, type=float, help='')\n",
    "        parser.add_argument('--epsilon', default=100000, type=int, help='Linear decay of exploration policy')\n",
    "        parser.add_argument('--seed', default=-1, type=int, help='')\n",
    "        parser.add_argument('--weight-decay', default=0.00001, type=float, help='weight decay for L2 Regularization loss')\n",
    "        parser.add_argument('--save_per_epochs', default=25, type=int, help='save model every X epochs')\n",
    "        parser.add_argument('--actor_critic_type', default='cnn', type=str, help='type of model to use (lpn, cnn, mlp)')\n",
    "        parser.add_argument('--k_neighbors', default=25, type=int, help='number of neighbors to consider')\n",
    "        parser.add_argument('--load_action_embedding', default=False, type=bool, help='load action embedding or not')\n",
    "        parser.add_argument('--latent_dim', default=48, type=int, help='latent dimension for encoder')\n",
    "        parser.add_argument('--chunk_size', default=10, type=int, help='chunk size for training encoder')\n",
    "        parser.add_argument('--epsilon_start', default=1.0, type=float, help='starting epsilon value, useful for resuming training')\n",
    "        parser.add_argument('--num_experiments_filter', default=20, type=int, help='number of problems on which to calculate the change percentage when filtering actions')\n",
    "        parser.add_argument('--filter_threshold', default=0.3, type=float, help='percentage of random problems an action must change not to be filtered')\n",
    "        parser.add_argument('--num_experiments_similarity', default=500, type=int, help='number of problems on which to calculate approximate similarity matrix between actions')\n",
    "        parser.add_argument('--max_embedding', default=10., type=float, help='Maximum value for numbers in the embedding matrix')\n",
    "        parser.add_argument('--min_embedding', default=-10., type=float, help='Minimum value for numbers in the embedding matrix')\n",
    "        return parser\n",
    "    else:\n",
    "        raise RuntimeError('undefined algorithm {}'.format(alg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.argv = ['notebook']  # Replace with a dummy argument list\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print('Using device: {}'.format(device))\n",
    "\n",
    "\n",
    "ptitle('WOLP_DDPG')\n",
    "warnings.filterwarnings('ignore')\n",
    "parser = init_parser('WOLP_DDPG')\n",
    "args = parser.parse_args()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_ids)[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "--------------------------------------------------\n",
      "Creating the action space\n",
      "Number of actions: 11310\n",
      "Filtered 0 out of 11310 actions\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m\n\u001b[1;32m     10\u001b[0m challenge_dictionary \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/RAW_DATA_DIR/arc-prize-2024/arc-agi_training_challenges.json\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     11\u001b[0m action_space_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_experiments_filter\u001b[39m\u001b[38;5;124m'\u001b[39m: args\u001b[38;5;241m.\u001b[39mnum_experiments_filter, \n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilter_threshold\u001b[39m\u001b[38;5;124m'\u001b[39m: args\u001b[38;5;241m.\u001b[39mfilter_threshold, \n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_experiments_similarity\u001b[39m\u001b[38;5;124m'\u001b[39m: args\u001b[38;5;241m.\u001b[39mnum_experiments_similarity,\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m'\u001b[39m: args\u001b[38;5;241m.\u001b[39mload_action_embedding\n\u001b[1;32m     16\u001b[0m     }\n\u001b[0;32m---> 18\u001b[0m action_space \u001b[38;5;241m=\u001b[39m ARCActionSpace(args)\n\u001b[1;32m     19\u001b[0m env \u001b[38;5;241m=\u001b[39m ARC_Env(challenge_dictionary, action_space)\n\u001b[1;32m     20\u001b[0m continuous \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Python/Personale/ARC with outputs/ARC/src/action_space.py:109\u001b[0m, in \u001b[0;36mARCActionSpace.__init__\u001b[0;34m(self, args, ColorSelector, Selector, Transformer)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc/embedded_space/embedded_actions.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcleaned_space, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_actions()\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Create the k-NN model for nearest neighbor search in the embedded space\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnearest_neighbors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Python/Personale/ARC with outputs/ARC/src/action_space.py:129\u001b[0m, in \u001b[0;36mARCActionSpace.embed_actions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Create an approximate similarity matrix of actions\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m cleaned_actions, similarity_matrix \u001b[38;5;241m=\u001b[39m create_approximate_similarity_matrix(\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m, args\u001b[38;5;241m.\u001b[39mnum_experiments_filter, args\u001b[38;5;241m.\u001b[39mfilter_threshold, args\u001b[38;5;241m.\u001b[39mnum_experiments_similarity\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Convert similarity to distance\u001b[39;00m\n\u001b[1;32m    133\u001b[0m distance_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m similarity_matrix\n",
      "File \u001b[0;32m~/Documents/Python/Personale/ARC with outputs/ARC/src/utils/action_space_embedding.py:307\u001b[0m, in \u001b[0;36mcreate_approximate_similarity_matrix\u001b[0;34m(action_space, num_experiments_filter, filter_threshold, num_experiments_similarity)\u001b[0m\n\u001b[1;32m    304\u001b[0m env \u001b[38;5;241m=\u001b[39m ARC_Env(challenge_dictionary\u001b[38;5;241m=\u001b[39mchallenge_dictionary, action_space\u001b[38;5;241m=\u001b[39maction_space)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# Filter actions based on their ability to change the environment.\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m cleaned_actions \u001b[38;5;241m=\u001b[39m filter_by_change(action_space, env, num_experiments_filter, filter_threshold)\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# Compute similarity matrices for each action component.\u001b[39;00m\n\u001b[1;32m    310\u001b[0m color_similarity \u001b[38;5;241m=\u001b[39m create_color_similarity_matrix(action_space, env, num_experiments_similarity)\n",
      "File \u001b[0;32m~/Documents/Python/Personale/ARC with outputs/ARC/src/utils/action_space_embedding.py:260\u001b[0m, in \u001b[0;36mfilter_by_change\u001b[0;34m(action_space, env, num_experiments, threshold)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_experiments):\n\u001b[1;32m    259\u001b[0m     random_problem \u001b[38;5;241m=\u001b[39m random_arc_problem(env)\n\u001b[0;32m--> 260\u001b[0m     new_state \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mact(random_problem, action)[\u001b[38;5;241m0\u001b[39m, :, :]\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(random_problem, new_state):\n\u001b[1;32m    262\u001b[0m         num_equal \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Python/Personale/ARC with outputs/ARC/src/enviroment.py:208\u001b[0m, in \u001b[0;36mARC_Env.act\u001b[0;34m(self, previous_state, action, fixed_color)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m#plot_selection(selected)\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(selected):\n\u001b[0;32m--> 208\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m transformation(grid \u001b[38;5;241m=\u001b[39m previous_state, selection \u001b[38;5;241m=\u001b[39m selected)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(previous_state, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Python/Personale/ARC with outputs/ARC/src/dsl/transform.py:139\u001b[0m, in \u001b[0;36mTransformer.fliph\u001b[0;34m(self, grid, selection)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03mFlip the grid along the specified axis.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m grid_3d \u001b[38;5;241m=\u001b[39m create_grid3d(grid, selection) \u001b[38;5;66;03m# Add an additional dimension to the grid by stacking it\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m bounding_rectangle \u001b[38;5;241m=\u001b[39m find_bounding_rectangle(selection) \u001b[38;5;66;03m# Find the bounding rectangle around the selection for each slice\u001b[39;00m\n\u001b[1;32m    140\u001b[0m flipped_bounding_rectangle \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mflip(bounding_rectangle, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# Flip the selection along the specified axis\u001b[39;00m\n\u001b[1;32m    141\u001b[0m grid_3d[bounding_rectangle] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mflip(grid_3d, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)[flipped_bounding_rectangle] \u001b[38;5;66;03m# Flip the bounding rectangle along the specified axis\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Python/Personale/ARC with outputs/ARC/src/dsl/utilities/transformation_utilities.py:37\u001b[0m, in \u001b[0;36mfind_bounding_rectangle\u001b[0;34m(input_array)\u001b[0m\n\u001b[1;32m     34\u001b[0m slice_2d \u001b[38;5;241m=\u001b[39m input_array[i]\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Calculate the bounding box\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m props \u001b[38;5;241m=\u001b[39m regionprops(slice_2d\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m))\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m props:\n\u001b[1;32m     39\u001b[0m     min_row, min_col, max_row, max_col \u001b[38;5;241m=\u001b[39m props[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbbox\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/skimage/measure/_regionprops.py:1389\u001b[0m, in \u001b[0;36mregionprops\u001b[0;34m(label_image, intensity_image, cache, extra_properties, spacing, offset)\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1387\u001b[0m     label \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1389\u001b[0m     props \u001b[38;5;241m=\u001b[39m RegionProperties(\n\u001b[1;32m   1390\u001b[0m         sl,\n\u001b[1;32m   1391\u001b[0m         label,\n\u001b[1;32m   1392\u001b[0m         label_image,\n\u001b[1;32m   1393\u001b[0m         intensity_image,\n\u001b[1;32m   1394\u001b[0m         cache,\n\u001b[1;32m   1395\u001b[0m         spacing\u001b[38;5;241m=\u001b[39mspacing,\n\u001b[1;32m   1396\u001b[0m         extra_properties\u001b[38;5;241m=\u001b[39mextra_properties,\n\u001b[1;32m   1397\u001b[0m         offset\u001b[38;5;241m=\u001b[39moffset_arr,\n\u001b[1;32m   1398\u001b[0m     )\n\u001b[1;32m   1399\u001b[0m     regions\u001b[38;5;241m.\u001b[39mappend(props)\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m regions\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/skimage/measure/_regionprops.py:351\u001b[0m, in \u001b[0;36mRegionProperties.__init__\u001b[0;34m(self, slice, label, label_image, intensity_image, cache_active, extra_properties, spacing, offset)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spacing \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     spacing \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ndim, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m--> 351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spacing \u001b[38;5;241m=\u001b[39m _normalize_spacing(spacing, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ndim)\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pixel_area \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mprod(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spacing)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extra_properties \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/skimage/measure/_regionprops_utils.py:626\u001b[0m, in \u001b[0;36m_normalize_spacing\u001b[0;34m(spacing, ndims)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(s, Real) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m spacing):\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    624\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElement of spacing isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt float or integer type, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspacing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(np\u001b[38;5;241m.\u001b[39misfinite(spacing)):\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    628\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid spacing parameter. All elements must be finite, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspacing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    629\u001b[0m     )\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spacing\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utils.util import get_output_folder, setup_logger\n",
    "from wolp_agent import WolpertingerAgent\n",
    "import os\n",
    "\n",
    "# Change the current working directory to the parent folder\n",
    "os.chdir('..')\n",
    "\n",
    "args.save_model_dir = get_output_folder('../output', args.env)\n",
    "\n",
    "challenge_dictionary = json.load(open('data/RAW_DATA_DIR/arc-prize-2024/arc-agi_training_challenges.json'))\n",
    "action_space_args = {\n",
    "        'num_experiments_filter': args.num_experiments_filter, \n",
    "        'filter_threshold': args.filter_threshold, \n",
    "        'num_experiments_similarity': args.num_experiments_similarity,\n",
    "        'load': args.load_action_embedding\n",
    "    }\n",
    "\n",
    "action_space = ARCActionSpace(args)\n",
    "env = ARC_Env(challenge_dictionary, action_space)\n",
    "continuous = None\n",
    "\n",
    "# discrete action for 1 dimension\n",
    "# TODO: change the nb_states to the shape of the grid\n",
    "nb_states = 1805  # 60 x 30 grid ravels to 1800 + 4 for the dimensions of the grid + 1 for cls embedding\n",
    "nb_actions = 20  # the dimension of actions, usually it is 1. Depend on the environment.\n",
    "continuous = False\n",
    "\n",
    "if args.seed > 0:\n",
    "    np.random.seed(args.seed)\n",
    "    env.seed(args.seed)\n",
    "\n",
    "agent_args = {\n",
    "    'nb_states': nb_states,\n",
    "    'nb_actions': nb_actions,\n",
    "    'args': args,\n",
    "    'k': args.k_neighbors,\n",
    "    'action_space': action_space\n",
    "}\n",
    "\n",
    "agent = WolpertingerAgent(**agent_args)\n",
    "\n",
    "if args.load:\n",
    "    agent.load_weights(args.load_model_dir)\n",
    "\n",
    "if args.gpu_ids[0] >= 0 and args.gpu_nums > 0 and torch.cuda.is_available():\n",
    "    agent.cuda_convert()\n",
    "\n",
    "# set logger, log args here\n",
    "log = {}\n",
    "if args.mode == 'train':\n",
    "    setup_logger('RS_log', r'{}/RS_train_log'.format(args.save_model_dir))\n",
    "elif args.mode == 'test':\n",
    "    setup_logger('RS_log', r'{}/RS_test_log'.format(args.save_model_dir))\n",
    "else:\n",
    "    raise RuntimeError('undefined mode {}'.format(args.mode))\n",
    "\n",
    "log['RS_log'] = logging.getLogger('RS_log')\n",
    "d_args = vars(args)\n",
    "d_args['max_actions'] = args.max_actions\n",
    "\n",
    "for key in agent_args.keys():\n",
    "    if key == 'args':\n",
    "        continue\n",
    "    d_args[key] = agent_args[key]\n",
    "for k in d_args.keys():\n",
    "    log['RS_log'].info('{0}: {1}'.format(k, d_args[k]))\n",
    "\n",
    "if args.mode == 'train':\n",
    "    print('Training')\n",
    "\n",
    "    train_args = {\n",
    "        'continuous': continuous,\n",
    "        'env': env,\n",
    "        'agent': agent,\n",
    "        'max_episode': args.max_episode,\n",
    "        'max_actions': args.max_actions,\n",
    "        'warmup': args.warmup,\n",
    "        'save_model_dir': args.save_model_dir,\n",
    "        'max_episode_length': args.max_episode_length,\n",
    "        'logger': log['RS_log'],\n",
    "        'save_per_epochs': args.save_per_epochs\n",
    "    }\n",
    "\n",
    "    train(**train_args)\n",
    "\n",
    "elif args.mode == 'test':\n",
    "\n",
    "    test_args = {\n",
    "        'env': env,\n",
    "        'agent': agent,\n",
    "        'model_path': args.load_model_dir,\n",
    "        'test_episode': args.test_episode,\n",
    "        'max_episode_length': args.max_episode_length,\n",
    "        'logger': log['RS_log'],\n",
    "    }\n",
    "\n",
    "    test(**test_args)\n",
    "\n",
    "else:\n",
    "    raise RuntimeError('undefined mode {}'.format(args.mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_challenge_dict = json.load(open('../data/RAW_DATA_DIR/arc-prize-2024/arc-agi_training_challenges.json'))\n",
    "training_solutions_dict = json.load(open('../data/RAW_DATA_DIR/arc-prize-2024/arc-agi_training_solutions.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difficult problems\n",
    "- a64e4611\n",
    "- cbded52d\n",
    "- 508bd3b6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Selections and Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# import the display_challenge function\n",
    "from dsl.utilities.plot import display_challenge, plot_grid\n",
    "\n",
    "# find the first challenge and solution\n",
    "challenge_key = '1f85a75f'\n",
    "challenge_key = random_keys[n]\n",
    "first_challenge = training_challenge_dict[challenge_key]\n",
    "first_solution = training_solutions_dict[challenge_key]\n",
    "\n",
    "print(f'Challenge key: {challenge_key}')\n",
    "\n",
    "# display the challenge\n",
    "display_challenge(challenge_key)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsl.utilities.plot import plot_grid \n",
    "arr2 = np.array([\n",
    "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 0, 2, 2],\n",
    "       [0, 0, 1, 1, 1, 1, 1, 0, 2, 2],\n",
    "       [0, 0, 0, 1, 1, 1, 0, 0, 2, 2],\n",
    "       [0, 0, 0, 1, 1, 1, 1, 1, 2, 2],\n",
    "       [0, 0, 0, 1, 0, 0, 1, 1, 2, 2],\n",
    "       [0, 0, 1, 1, 1, 1, 1, 0, 2, 2],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "arr = np.array([\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 4, 8, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 9, 4, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 2, 1, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 1, 2, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "])\n",
    "\n",
    "arr = np.array([\n",
    "              [2, 2, 1],\n",
    "              [2, 3, 1],\n",
    "              [1, 1, 1],\n",
    "              ])\n",
    "\n",
    "# plot the array as an image\n",
    "plot_grid(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsl.color_select import ColorSelector\n",
    "\n",
    "colsel = ColorSelector()\n",
    "\n",
    "popular_color = colsel.mostcolor(arr)\n",
    "print(f'Most popular color: {popular_color}')\n",
    "least_popular_color = colsel.leastcolor(arr)\n",
    "print(f'Least popular color: {least_popular_color}')\n",
    "\n",
    "second_most_popular_color = colsel.rankcolor(arr, 1)\n",
    "print(f'Second most popular color: {second_most_popular_color}')\n",
    "\n",
    "color_of_second_biggest_shape = colsel.rank_largest_shape_color_nodiag(arr, 1)\n",
    "print(f'Color of second biggest shape: {color_of_second_biggest_shape}')\n",
    "\n",
    "color_of_second_biggest_shape = colsel.rank_largest_shape_color_diag(arr, 1)\n",
    "print(f'Color of second biggest shape: {color_of_second_biggest_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsl.select import Selector\n",
    "from dsl.utilities.plot import plot_selection\n",
    "from skimage.segmentation import find_boundaries\n",
    "\n",
    "sel = Selector()\n",
    "\n",
    "print('Selecting by color')\n",
    "selection = sel.select_color(arr, 1)\n",
    "plot_selection(selection)\n",
    "\n",
    "print('Selecting colored rectange combinations')\n",
    "selection3 = sel.select_connected_shapes(arr, 0)\n",
    "plot_selection(selection3)\n",
    "\n",
    "print('Selecting cells adjacent to color')\n",
    "selection4 = sel.select_connected_shapes(arr, 1)\n",
    "plot_selection(selection4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Reinforcement learning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from action_space import ARCActionSpace\n",
    "from dsl.transform import Transformer\n",
    "from dsl.utilities.plot import plot_grid_3d\n",
    "trn = Transformer()\n",
    "\n",
    "action_space = ARCActionSpace(colsel, sel, trn)\n",
    "\n",
    "\n",
    "proto_action = np.array([0.5, 0.5, 0.5])\n",
    "distances, indices, actions = action_space.search_point(proto_action, k=100)\n",
    "print('Closest actions:', actions[:5])\n",
    "print(actions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enviroment import ARC_Env\n",
    "\n",
    "env = ARC_Env(training_challenge_dict, action_space=action_space, seed=0)\n",
    "seed = np.random.seed(1)\n",
    "random.seed(0)\n",
    "env.reset()\n",
    "\n",
    "i = 0\n",
    "while False:\n",
    "    i += 1\n",
    "    action = random.choice(action_space.space)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    if i % 1000 == 0:\n",
    "        print(f'Step: {i}')\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def enlarge(grid, selection, radius):\n",
    "    \"\"\"\n",
    "    Enlarges the selected shape in the grid by a given radius, adding rows and columns of zeros between existing rows and columns.\n",
    "    \n",
    "    Args:\n",
    "        grid (np.ndarray): The original input grid\n",
    "        selection (np.ndarray): A binary mask indicating the shape (same shape as grid)\n",
    "        radius (int): Number of cells to expand outward\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: A new grid with the enlarged shape\n",
    "    #TODO: In the DRL environment radius will probably have to be an iterable for low numbers (likely between 1 and 3)\n",
    "    \"\"\"\n",
    "    # Ensure grid and selection are the same shape\n",
    "    assert grid.shape == selection.shape, \"Grid and each selection layer must have the same shape.\"\n",
    "    \n",
    "    rows, cols = grid.shape\n",
    "    # Create a larger grid with interstitial spaces\n",
    "    new_rows = rows * 2 - 1\n",
    "    new_cols = cols * 2 - 1\n",
    "    \n",
    "    # Add padding for the expansion\n",
    "    pad_rows = radius\n",
    "    pad_cols = radius\n",
    "    total_rows = new_rows + 2 * pad_rows\n",
    "    total_cols = new_cols + 2 * pad_cols\n",
    "    \n",
    "    # Create padded grid with zeros\n",
    "    padded_grid = np.zeros((total_rows, total_cols), dtype=grid.dtype)\n",
    "    padded_selection = np.zeros((total_rows, total_cols), dtype=selection.dtype)\n",
    "    \n",
    "    \n",
    "    # Fill original positions (accounting for padding offset)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if selection[i, j] == 1 and grid[i, j] == 1:\n",
    "                padded_grid[pad_rows + i*2, pad_cols + j*2] = 1\n",
    "                padded_selection[pad_rows + i*2, pad_cols + j*2] = 1\n",
    "    \n",
    "    # Find all non-zero elements in the grid (enlargement origins)\n",
    "    enlargement_origins = np.argwhere(padded_grid != 0)\n",
    "\n",
    "    # Iterate over each origin\n",
    "    for origin in enlargement_origins:\n",
    "        row, col = origin\n",
    "\n",
    "        # Vertical (upwards)\n",
    "        for r in range(1, radius + 1):\n",
    "            if row - r >= 0:  # Ensure we don't go out of bounds\n",
    "                padded_grid[row - r, col] = 1\n",
    "\n",
    "        # Horizontal (rightwards)\n",
    "        for c in range(1, radius + 1):\n",
    "            if col + c < padded_grid.shape[1]:  # Ensure we don't go out of bounds\n",
    "                padded_grid[row, col + c] = 1\n",
    "\n",
    "        # Diagonal (right-up)\n",
    "        for d in range(1, radius + 1):\n",
    "            if row - d >= 0 and col + d < padded_grid.shape[1]:  # Ensure we don't go out of bounds\n",
    "                padded_grid[row - d, col + d] = 1\n",
    "\n",
    "    return padded_grid\n",
    "\n",
    "\n",
    "# Test the function\n",
    "grid = np.array([\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0],\n",
    "])\n",
    "\n",
    "selection = np.array([\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0],\n",
    "])\n",
    "\n",
    "# Enlarge the selection with a radius of 1 and include diagonal neighbors\n",
    "result = enlarge(grid, selection, radius=1)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nOriginal Grid:\")\n",
    "print(grid)\n",
    "print(\"\\nEnlarged Grid:\")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_paths(x, y, last_move=None, consecutive=0, memo={}):\n",
    "    # Base case: reached destination\n",
    "    if x == 7 and y == 4:\n",
    "        return 1\n",
    "    # Base case: out of bounds\n",
    "    if x > 7 or y > 4:\n",
    "        return 0\n",
    "    # Memoization key\n",
    "    key = (x, y, last_move, consecutive)\n",
    "    if key in memo:\n",
    "        return memo[key]\n",
    "    \n",
    "    # Recursive case\n",
    "    ways = 0\n",
    "    # Move right if not violating the consecutive constraint\n",
    "    if last_move != 'R' or consecutive < 2:\n",
    "        ways += count_paths(x + 1, y, 'R', consecutive + 1 if last_move == 'R' else 1, memo)\n",
    "    # Move up if not violating the consecutive constraint\n",
    "    if last_move != 'U' or consecutive < 2:\n",
    "        ways += count_paths(x, y + 1, 'U', consecutive + 1 if last_move == 'U' else 1, memo)\n",
    "    \n",
    "    memo[key] = ways\n",
    "    return ways\n",
    "\n",
    "# Compute the number of ways\n",
    "result = count_paths(0, 0)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.array([\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0],\n",
    "])\n",
    "\n",
    "grid = np.expand_dims(grid, axis=0)\n",
    "print(grid.shape)\n",
    "\n",
    "def grid_to_tokens(grid):\n",
    "    \"\"\"\n",
    "    Converts a grid to a list of tokens.\n",
    "    \n",
    "    Args:\n",
    "        grid (np.ndarray): The input grid\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of tokens\n",
    "    \"\"\"\n",
    "    tokens = np.zeros(grid.size +2, dtype=np.float32)\n",
    "    d, nrows, ncols = grid.shape\n",
    "    tokens[0] = nrows\n",
    "    tokens[1] = ncols\n",
    "    tokens[2:] = grid.flatten()\n",
    "    return tokens\n",
    "\n",
    "tokens = grid_to_tokens(grid)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def downscale(grid, scale_factor, aggregation_fn=np.max):\n",
    "    \"\"\"\n",
    "    Downscales a grid by a given scale factor using a specified aggregation function.\n",
    "    \n",
    "    Args:\n",
    "        grid (np.ndarray): The input grid to downscale.\n",
    "        scale_factor (int): The factor by which to reduce the grid's size.\n",
    "        aggregation_fn (callable): The function to aggregate values in each block (default: np.max).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: The downscaled grid.\n",
    "    \"\"\"\n",
    "    assert grid.shape[0] % scale_factor == 0 and grid.shape[1] % scale_factor == 0, \\\n",
    "        \"Grid dimensions must be divisible by scale_factor.\"\n",
    "    \n",
    "    rows, cols = grid.shape\n",
    "    new_rows = rows // scale_factor\n",
    "    new_cols = cols // scale_factor\n",
    "\n",
    "    # Create the downscaled grid\n",
    "    downscaled_grid = np.zeros((new_rows, new_cols), dtype=grid.dtype)\n",
    "\n",
    "    # Iterate over blocks and apply aggregation function\n",
    "    for i in range(new_rows):\n",
    "        for j in range(new_cols):\n",
    "            block = grid[\n",
    "                i * scale_factor:(i + 1) * scale_factor,\n",
    "                j * scale_factor:(j + 1) * scale_factor\n",
    "            ]\n",
    "            downscaled_grid[i, j] = aggregation_fn(block)\n",
    "\n",
    "    return downscaled_grid\n",
    "\n",
    "# Test the function\n",
    "grid = np.array([\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 0, 0],\n",
    "    [1, 1, 1, 1, 0, 0],\n",
    "    [1, 1, 1, 1, 0, 0],\n",
    "    [1, 1, 1, 1, 0, 0]\n",
    "])\n",
    "\n",
    "selection = np.array([\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0]\n",
    "])\n",
    "\n",
    "# Enlarge the selection with a radius of 1\n",
    "result = downscale(grid, 3)\n",
    "\n",
    "print(\"\\nOriginal Grid:\")\n",
    "print(grid)\n",
    "print(\"\\nEnlarged Grid:\")\n",
    "print(result.astype(int))  # Convert to int for cleaner printing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dsl.select import Selector\n",
    "from dsl.transform import Transformer     \n",
    "from dsl.transform import Transformer\n",
    "from dsl.utilities.plot import plot_grid_3d, plot_selection, plot_grid\n",
    "\n",
    "\n",
    "arr = np.array([\n",
    "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 0, 2, 2],\n",
    "       [0, 0, 1, 1, 1, 1, 1, 0, 2, 2],\n",
    "       [0, 0, 0, 1, 1, 1, 0, 0, 2, 2],\n",
    "       [0, 0, 0, 1, 1, 1, 1, 1, 2, 2],\n",
    "       [0, 0, 0, 1, 0, 0, 1, 1, 2, 2],\n",
    "       [0, 0, 1, 1, 1, 1, 1, 0, 2, 2],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "# plot the array as an image\n",
    "plot_grid(arr)\n",
    "sel = Selector(arr.shape)\n",
    "trn = Transformer()\n",
    "print('Selecting cells adjacent to color')\n",
    "selection4 = sel.select_connected_shapes(arr, 1)\n",
    "plot_selection(selection4)\n",
    "print('Shift cells')\n",
    "transformed5 = trn.change_background_color(arr, selection4,7)\n",
    "plot_grid_3d(transformed5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dsl.select import Selector\n",
    "from dsl.transform import Transformer     \n",
    "from dsl.transform import Transformer\n",
    "from dsl.utilities.plot import plot_grid_3d, plot_selection, plot_grid\n",
    "\n",
    "\n",
    "arr1 = np.array([\n",
    "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 0, 2, 2],\n",
    "       [0, 0, 1, 1, 1, 1, 1, 0, 2, 2],\n",
    "       [0, 0, 0, 1, 1, 1, 0, 0, 2, 2],\n",
    "       [0, 0, 0, 1, 1, 1, 1, 1, 2, 2],\n",
    "       [0, 0, 0, 1, 0, 0, 1, 1, 2, 2],\n",
    "       [0, 0, 1, 1, 1, 1, 1, 0, 2, 2],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "arr2 = np.array([\n",
    "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 0, 2, 2],\n",
    "       [0, 0, 1, 1, 1, 1, 1, 0, 2, 2],\n",
    "       [0, 0, 0, 1, 1, 1, 0, 0, 2, 2],\n",
    "       [0, 0, 0, 1, 1, 1, 1, 1, 2, 2],\n",
    "       [0, 0, 0, 1, 0, 0, 1, 1, 2, 2],\n",
    "       [0, 0, 1, 1, 1, 1, 1, 0, 2, 2],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "# plot the array as an image\n",
    "plot_grid(arr1)\n",
    "sel1 = Selector(arr1.shape)\n",
    "sel2 = Selector(arr2.shape)\n",
    "trn = Transformer()\n",
    "print('Selecting cells adjacent to color')\n",
    "selection4 = sel1.select_connected_shapes(arr1, 1)\n",
    "selection5 = sel2.select_connected_shapes(arr2, 1)\n",
    "plot_selection(selection4)\n",
    "print('Vupscale')\n",
    "transformed5 = trn.vupscale(arr1, selection4, 2)\n",
    "plot_grid_3d(transformed5)\n",
    "print('Vectorized Vupscale')\n",
    "transformed6 = trn.vectorized_vupscale(arr2, selection4, 2)\n",
    "plot_grid_3d(transformed6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dsl.select import Selector\n",
    "from dsl.transform import Transformer     \n",
    "from dsl.transform import Transformer\n",
    "from dsl.utilities.plot import plot_grid_3d, plot_selection, plot_grid\n",
    "from dsl.utilities.transformation_utilities import center_of_mass\n",
    "\n",
    "\n",
    "arr1 = np.array([\n",
    "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "       [2, 0, 0, 0, 0, 0, 0, 0, 0, 2],\n",
    "       [2, 0, 1, 1, 1, 1, 0, 0, 0, 2],\n",
    "       [2, 0, 1, 0, 0, 1, 0, 0, 0, 2],\n",
    "       [2, 0, 1, 1, 1, 1, 0, 0, 0, 2],\n",
    "       [2, 0, 0, 0, 0, 0, 1, 1, 1, 2],\n",
    "       [2, 0, 0, 0, 0, 0, 1, 0, 1, 2],\n",
    "       [2, 0, 0, 0, 0, 0, 1, 1, 1, 2],\n",
    "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])\n",
    "\n",
    "arr2 = np.array([\n",
    "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "       [2, 0, 0, 0, 0, 0, 0, 0, 0, 2],\n",
    "       [2, 0, 1, 1, 1, 1, 0, 0, 0, 2],\n",
    "       [2, 0, 1, 0, 0, 1, 0, 0, 0, 2],\n",
    "       [2, 0, 1, 1, 1, 1, 0, 0, 0, 2],\n",
    "       [2, 0, 0, 0, 0, 0, 1, 1, 1, 2],\n",
    "       [2, 0, 0, 0, 0, 0, 1, 0, 1, 2],\n",
    "       [2, 0, 0, 0, 0, 0, 1, 1, 1, 2],\n",
    "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])\n",
    "\n",
    "# plot the array as an image\n",
    "plot_grid(arr1)\n",
    "sel1 = Selector(arr1.shape)\n",
    "sel2 = Selector(arr2.shape)\n",
    "trn = Transformer()\n",
    "print('Selecting cells adjacent to color')\n",
    "selection4 = sel1.select_connected_shapes(arr1, 1)\n",
    "selection5 = sel2.select_connected_shapes(arr2, 1)\n",
    "plot_selection(selection4)\n",
    "print('Vupscale')\n",
    "transformed5 = trn.vupscale(arr1, selection4, 2)\n",
    "plot_grid_3d(transformed5)\n",
    "print('Vectorized Vupscale')\n",
    "transformed6 = trn.vectorized_vupscale(arr2, selection4, 2)\n",
    "plot_grid_3d(transformed6)\n",
    "\n",
    "\n",
    "\n",
    "CoM1 = center_of_mass(selection4[0])\n",
    "CoM2 = center_of_mass(selection4[1])\n",
    "print(f'Center of mass of shape 0: {CoM1}')\n",
    "print(f'Center of mass of shape 1: {CoM2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def maximum_overlap_regions_old(array1, array2):\n",
    "        \"\"\"\n",
    "        Vectorized calculation of maximum overlap between two 2D arrays.\n",
    "        \"\"\"\n",
    "        shape1 = array1.shape\n",
    "        shape2 = array2.shape\n",
    "        \n",
    "        # Calculate possible positions for sliding array2 over array1\n",
    "        offsets_i = np.arange(-shape2[0] + 1, shape1[0])\n",
    "        offsets_j = np.arange(-shape2[1] + 1, shape1[1])\n",
    "        \n",
    "        # Create grids for all possible offsets\n",
    "        grid_i, grid_j = np.meshgrid(offsets_i, offsets_j, indexing='ij')\n",
    "        \n",
    "        # Calculate the valid overlap regions for each position\n",
    "        row_start1 = np.maximum(0, grid_i)\n",
    "        row_end1 = np.minimum(shape1[0], grid_i + shape2[0])\n",
    "        col_start1 = np.maximum(0, grid_j)\n",
    "        col_end1 = np.minimum(shape1[1], grid_j + shape2[1])\n",
    "        \n",
    "        row_start2 = np.maximum(0, -grid_i)\n",
    "        row_end2 = row_start2 + (row_end1 - row_start1)\n",
    "        col_start2 = np.maximum(0, -grid_j)\n",
    "        col_end2 = col_start2 + (col_end1 - col_start1)\n",
    "        \n",
    "        # Calculate overlap scores for all positions\n",
    "        max_overlap_score = 0\n",
    "        best_overlap1 = None\n",
    "        best_overlap2 = None\n",
    "        \n",
    "        for idx in np.ndindex(grid_i.shape):\n",
    "            r1s, r1e = row_start1[idx], row_end1[idx]\n",
    "            c1s, c1e = col_start1[idx], col_end1[idx]\n",
    "            r2s, r2e = row_start2[idx], row_end2[idx]\n",
    "            c2s, c2e = col_start2[idx], col_end2[idx]\n",
    "            \n",
    "            region1 = array1[r1s:r1e, c1s:c1e]\n",
    "            region2 = array2[r2s:r2e, c2s:c2e]\n",
    "            \n",
    "            overlap_score = np.sum(region1 == region2)\n",
    "            \n",
    "            if overlap_score > max_overlap_score:\n",
    "                max_overlap_score = overlap_score\n",
    "                best_overlap1 = (slice(r1s, r1e), slice(c1s, c1e))\n",
    "                best_overlap2 = (slice(r2s, r2e), slice(c2s, c2e))\n",
    "        \n",
    "        return best_overlap1, best_overlap2\n",
    "# Functions to test\n",
    "def test_overlap_functions():\n",
    "    def generate_random_grids(max_size=30):\n",
    "        size1 = np.random.randint(2, max_size+1, size=2)  # Random size for grid 1\n",
    "        size2 = np.random.randint(2, max_size+1, size=2)  # Random size for grid 2\n",
    "        grid1 = np.random.randint(0, 5, size=size1)       # Random grid 1 with values 0-4\n",
    "        grid2 = np.random.randint(0, 5, size=size2)       # Random grid 2 with values 0-4\n",
    "        return grid1, grid2\n",
    "\n",
    "    num_tests = 10\n",
    "    max_size = 5\n",
    "\n",
    "    old_times = []\n",
    "    new_times = []\n",
    "\n",
    "    for test_idx in range(num_tests):\n",
    "        grid1, grid2 = generate_random_grids(max_size)\n",
    "\n",
    "        # Test old function\n",
    "        start_time = time.time()\n",
    "        old_result1, old_result2 = maximum_overlap_regions_old(grid1, grid2)\n",
    "        old_times.append(time.time() - start_time)\n",
    "\n",
    "        # Test new function\n",
    "        start_time = time.time()\n",
    "        new_result1, new_result2 = maximum_overlap_regions(grid1, grid2)\n",
    "        new_times.append(time.time() - start_time)\n",
    "\n",
    "        # Verify that the results match\n",
    "        if old_result1 != new_result1 or old_result2 != new_result2:\n",
    "            print(f\"Mismatch on test {test_idx}:\")\n",
    "            print(\"Grid1:\")\n",
    "            print(grid1)\n",
    "            print(\"Grid2:\")\n",
    "            print(grid2)\n",
    "            print(\"Old function results:\")\n",
    "            print(old_result1, old_result2)\n",
    "            print(grid1[old_result1])\n",
    "            print(grid2[old_result2])\n",
    "            print('Overlap:', np.sum(grid1[old_result1] == grid2[old_result2]))\n",
    "            print('')\n",
    "            print(\"New function results:\")\n",
    "            print(new_result1, new_result2)\n",
    "            print(grid1[new_result1])\n",
    "            print(grid2[new_result2])\n",
    "            print('Overlap:', np.sum(grid1[new_result1] == grid2[new_result2]))\n",
    "            raise AssertionError(f\"Mismatch in results on test {test_idx}\")\n",
    "\n",
    "        print(f\"Test {test_idx + 1}/{num_tests}: PASSED\")\n",
    "\n",
    "    print(f\"\\nAverage time for old function: {np.mean(old_times):.6f} seconds\")\n",
    "    print(f\"Average time for new function: {np.mean(new_times):.6f} seconds\")\n",
    "\n",
    "# Run the tests\n",
    "test_overlap_functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import inspect\n",
    "import torch\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from dsl.utilities.plot import plot_grid, plot_grid_3d, plot_selection, display_challenge\n",
    "from action_space import ARCActionSpace\n",
    "from dsl.transform import Transformer\n",
    "from enviroment import ARC_Env\n",
    "\n",
    "from cleaner import cleaner\n",
    "\n",
    "cleaner()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
