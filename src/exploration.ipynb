{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "from train_test import train, test\n",
    "import warnings\n",
    "import json\n",
    "from arg_parser import init_parser\n",
    "from setproctitle import setproctitle as ptitle\n",
    "from enviroment import ARC_Env\n",
    "import gymnasium as gym\n",
    "from action_space import ARCActionSpace\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def init_parser(alg):\n",
    "\n",
    "    if alg == 'WOLP_DDPG':\n",
    "        parser = argparse.ArgumentParser(description='WOLP_DDPG')\n",
    "        parser.add_argument('--env', default='ARC', metavar='ENV', help='environment to train on')\n",
    "        parser.add_argument('--gamma', type=float, default=0.99, metavar='G', help='discount factor for rewards (default: 0.99)')\n",
    "        parser.add_argument('--max-episode-length', type=int, default=50, metavar='M', help='maximum length of an episode (default: 1440)') #NOTE: changed from 1440 to 5\n",
    "        parser.add_argument('--load', default=False, metavar='L', help='load a trained model')\n",
    "        parser.add_argument('--load-model-dir', default='ARC-run975', metavar='LMD', help='folder to load trained models from')\n",
    "        parser.add_argument('--gpu-ids', type=int, default=[1], nargs='+', help='GPUs to use [-1 CPU only]')\n",
    "        parser.add_argument('--gpu-nums', type=int, default=8, help='#GPUs to use (default: 1)')\n",
    "        parser.add_argument('--max-episode', type=int, default=20000, help='maximum #episode.')\n",
    "        parser.add_argument('--test-episode', type=int, default=20, help='maximum testing #episode.')\n",
    "        parser.add_argument('--max-actions', default=1e8, type=int, help='# max actions')\n",
    "        parser.add_argument('--id', default='0', type=str, help='experiment id')\n",
    "        parser.add_argument('--mode', default='train', type=str, help='support option: train/test')\n",
    "        parser.add_argument('--hidden1', default=256, type=int, help='hidden num of first fully connect layer')\n",
    "        parser.add_argument('--hidden2', default=128, type=int, help='hidden num of second fully connect layer')\n",
    "        parser.add_argument('--c-lr', default=1e-3, type=float, help='critic net learning rate')\n",
    "        parser.add_argument('--p-lr', default=1e-3, type=float, help='policy net learning rate (only for DDPG)')\n",
    "        parser.add_argument('--warmup', default=500, type=int, help='time without training but only filling the replay memory')\n",
    "        parser.add_argument('--bsize', default=32, type=int, help='minibatch size')\n",
    "        parser.add_argument('--rmsize', default=100000, type=int, help='memory size')\n",
    "        parser.add_argument('--window_length', default=1, type=int, help='')\n",
    "        parser.add_argument('--tau-update', default=0.0005, type=float, help='moving average for target network')\n",
    "        parser.add_argument('--ou_theta', default=0.5, type=float, help='noise theta')\n",
    "        parser.add_argument('--ou_sigma', default=0.2, type=float, help='noise sigma')\n",
    "        parser.add_argument('--ou_mu', default=0.0, type=float, help='noise mu')\n",
    "        parser.add_argument('--init_w', default=0.003, type=float, help='')\n",
    "        parser.add_argument('--epsilon', default=100000, type=int, help='Linear decay of exploration policy')\n",
    "        parser.add_argument('--seed', default=-1, type=int, help='')\n",
    "        parser.add_argument('--weight-decay', default=0.00001, type=float, help='weight decay for L2 Regularization loss')\n",
    "        parser.add_argument('--save_per_epochs', default=25, type=int, help='save model every X epochs')\n",
    "        parser.add_argument('--actor_critic_type', default='cnn', type=str, help='type of model to use (lpn, cnn, mlp)')\n",
    "        parser.add_argument('--k_neighbors', default=25, type=int, help='number of neighbors to consider')\n",
    "        parser.add_argument('--load_action_embedding', default=True, type=bool, help='load action embedding or not')\n",
    "        parser.add_argument('--latent_dim', default=48, type=int, help='latent dimension for encoder')\n",
    "        parser.add_argument('--chunk_size', default=10, type=int, help='chunk size for training encoder')\n",
    "        parser.add_argument('--epsilon_start', default=1.0, type=float, help='starting epsilon value, useful for resuming training')\n",
    "        parser.add_argument('--num_experiments_filter', default=20, type=int, help='number of problems on which to calculate the change percentage when filtering actions')\n",
    "        parser.add_argument('--filter_threshold', default=0.3, type=float, help='percentage of random problems an action must change not to be filtered')\n",
    "        parser.add_argument('--num_experiments_similarity', default=500, type=int, help='number of problems on which to calculate approximate similarity matrix between actions')\n",
    "        parser.add_argument('--max_embedding', default=10., type=float, help='Maximum value for numbers in the embedding matrix')\n",
    "        parser.add_argument('--min_embedding', default=-10., type=float, help='Minimum value for numbers in the embedding matrix')\n",
    "        return parser\n",
    "    else:\n",
    "        raise RuntimeError('undefined algorithm {}'.format(alg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.argv = ['notebook']  # Replace with a dummy argument list\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print('Using device: {}'.format(device))\n",
    "\n",
    "\n",
    "ptitle('WOLP_DDPG')\n",
    "warnings.filterwarnings('ignore')\n",
    "parser = init_parser('WOLP_DDPG')\n",
    "args = parser.parse_args()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_ids)[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "--------------------------------------------------\n",
      "Creating the action space\n",
      "Number of actions not filtered: 11310\n",
      "Number of actions filtered: 5494\n",
      "NearestNeighbors model created with None neighbors\n",
      "--------------------------------------------------\n",
      "Using device: mps for ddpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 18:22:26,404 : env: ARC\n",
      "2025-02-06 18:22:26,404 : gamma: 0.99\n",
      "2025-02-06 18:22:26,404 : max_episode_length: 50\n",
      "2025-02-06 18:22:26,405 : load: False\n",
      "2025-02-06 18:22:26,405 : load_model_dir: ARC-run975\n",
      "2025-02-06 18:22:26,405 : gpu_ids: [1]\n",
      "2025-02-06 18:22:26,406 : gpu_nums: 8\n",
      "2025-02-06 18:22:26,406 : max_episode: 20000\n",
      "2025-02-06 18:22:26,407 : test_episode: 20\n",
      "2025-02-06 18:22:26,407 : max_actions: 100000000.0\n",
      "2025-02-06 18:22:26,407 : id: 0\n",
      "2025-02-06 18:22:26,408 : mode: train\n",
      "2025-02-06 18:22:26,408 : hidden1: 256\n",
      "2025-02-06 18:22:26,408 : hidden2: 128\n",
      "2025-02-06 18:22:26,409 : c_lr: 0.001\n",
      "2025-02-06 18:22:26,409 : p_lr: 0.001\n",
      "2025-02-06 18:22:26,409 : warmup: 500\n",
      "2025-02-06 18:22:26,410 : bsize: 32\n",
      "2025-02-06 18:22:26,410 : rmsize: 100000\n",
      "2025-02-06 18:22:26,410 : window_length: 1\n",
      "2025-02-06 18:22:26,411 : tau_update: 0.0005\n",
      "2025-02-06 18:22:26,411 : ou_theta: 0.5\n",
      "2025-02-06 18:22:26,411 : ou_sigma: 0.2\n",
      "2025-02-06 18:22:26,412 : ou_mu: 0.0\n",
      "2025-02-06 18:22:26,412 : init_w: 0.003\n",
      "2025-02-06 18:22:26,412 : epsilon: 100000\n",
      "2025-02-06 18:22:26,413 : seed: -1\n",
      "2025-02-06 18:22:26,413 : weight_decay: 1e-05\n",
      "2025-02-06 18:22:26,413 : save_per_epochs: 25\n",
      "2025-02-06 18:22:26,414 : actor_critic_type: cnn\n",
      "2025-02-06 18:22:26,414 : k_neighbors: 25\n",
      "2025-02-06 18:22:26,414 : load_action_embedding: True\n",
      "2025-02-06 18:22:26,415 : latent_dim: 48\n",
      "2025-02-06 18:22:26,415 : chunk_size: 10\n",
      "2025-02-06 18:22:26,415 : epsilon_start: 1.0\n",
      "2025-02-06 18:22:26,416 : num_experiments_filter: 20\n",
      "2025-02-06 18:22:26,418 : filter_threshold: 0.3\n",
      "2025-02-06 18:22:26,421 : num_experiments_similarity: 500\n",
      "2025-02-06 18:22:26,423 : max_embedding: 10.0\n",
      "2025-02-06 18:22:26,423 : min_embedding: -10.0\n",
      "2025-02-06 18:22:26,424 : save_model_dir: ../output/ARC-run1010\n",
      "2025-02-06 18:22:26,427 : nb_states: 1805\n",
      "2025-02-06 18:22:26,427 : nb_actions: 20\n",
      "2025-02-06 18:22:26,428 : k: 25\n",
      "2025-02-06 18:22:26,429 : action_space: <action_space.ARCActionSpace object at 0x31e42c590>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps for Wolpertinger agent\n",
      "Using 25 nearest neighbors for Wolpertinger agent\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 18:22:26,925 : Ep:0    | R:-226.62 | Steps:   50 | Equal:   22 | Rs>0:    0 | eps: 1.000\n",
      "2025-02-06 18:22:27,269 : Ep:1    | R:-231.21 | Steps:   50 | Equal:   40 | Rs>0:    0 | eps: 1.000\n",
      "2025-02-06 18:22:27,649 : Ep:2    | R:-179.50 | Steps:   50 | Equal:   14 | Rs>0:    2 | eps: 1.000\n",
      "2025-02-06 18:22:28,011 : Ep:3    | R:-287.50 | Steps:   50 | Equal:   43 | Rs>0:    0 | eps: 1.000\n",
      "2025-02-06 18:22:28,427 : Ep:4    | R:-198.00 | Steps:   50 | Equal:   16 | Rs>0:    4 | eps: 1.000\n",
      "2025-02-06 18:22:28,806 : Ep:5    | R:-169.97 | Steps:   50 | Equal:   20 | Rs>0:    0 | eps: 1.000\n",
      "2025-02-06 18:22:29,186 : Ep:6    | R:-238.00 | Steps:   50 | Equal:   46 | Rs>0:    0 | eps: 1.000\n",
      "2025-02-06 18:22:29,482 : Ep:7    | R:-217.33 | Steps:   50 | Equal:   46 | Rs>0:    1 | eps: 1.000\n",
      "2025-02-06 18:22:29,728 : Ep:8    | R:-246.00 | Steps:   50 | Equal:   48 | Rs>0:    0 | eps: 1.000\n",
      "2025-02-06 18:22:30,224 : Ep:9    | R:-149.50 | Steps:   50 | Equal:    9 | Rs>0:    3 | eps: 1.000\n",
      "2025-02-06 18:22:33,932 : Ep:10   | R: -92.33 | Steps:    5 | Equal:    1 | Rs>0:    3 | eps: 1.000\n",
      "2025-02-06 18:22:39,264 : Ep:11   | R:-165.54 | Steps:   11 | Equal:    2 | Rs>0:    0 | eps: 1.000\n",
      "2025-02-06 18:22:43,583 : Ep:12   | R:-155.12 | Steps:    9 | Equal:    3 | Rs>0:    3 | eps: 1.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 84\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     71\u001b[0m     train_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontinuous\u001b[39m\u001b[38;5;124m'\u001b[39m: continuous,\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menv\u001b[39m\u001b[38;5;124m'\u001b[39m: env,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_per_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m: args\u001b[38;5;241m.\u001b[39msave_per_epochs\n\u001b[1;32m     82\u001b[0m     }\n\u001b[0;32m---> 84\u001b[0m     train(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrain_args)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     88\u001b[0m     test_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menv\u001b[39m\u001b[38;5;124m'\u001b[39m: env,\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m'\u001b[39m: agent,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogger\u001b[39m\u001b[38;5;124m'\u001b[39m: log[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRS_log\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     95\u001b[0m     }\n",
      "File \u001b[0;32m~/Documents/Python/Personale/ARC with outputs/ARC/src/train_test.py:45\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(continuous, env, agent, max_episode, max_actions, warmup, save_model_dir, max_episode_length, logger, save_per_epochs)\u001b[0m\n\u001b[1;32m     43\u001b[0m agent\u001b[38;5;241m.\u001b[39mobserve(r_t, s_t1, shape1, done)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m>\u001b[39m warmup:\n\u001b[0;32m---> 45\u001b[0m     agent\u001b[38;5;241m.\u001b[39mupdate_policy()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# update\u001b[39;00m\n\u001b[1;32m     48\u001b[0m step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Python/Personale/ARC with outputs/ARC/src/wolp_agent.py:259\u001b[0m, in \u001b[0;36mWolpertingerAgent.update_policy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic_gradients\u001b[38;5;241m.\u001b[39mappend(critic_gradient_norm)\n\u001b[1;32m    258\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m--> 259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic_optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Actor update\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_optim\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Zero gradients before backward\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:244\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    232\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    234\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    235\u001b[0m         group,\n\u001b[1;32m    236\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m         state_steps,\n\u001b[1;32m    242\u001b[0m     )\n\u001b[0;32m--> 244\u001b[0m     adam(\n\u001b[1;32m    245\u001b[0m         params_with_grad,\n\u001b[1;32m    246\u001b[0m         grads,\n\u001b[1;32m    247\u001b[0m         exp_avgs,\n\u001b[1;32m    248\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    249\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    250\u001b[0m         state_steps,\n\u001b[1;32m    251\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    252\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    253\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    254\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    255\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    256\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    257\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    258\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    259\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    260\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    261\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    262\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    263\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    264\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    265\u001b[0m     )\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:876\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    874\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 876\u001b[0m func(\n\u001b[1;32m    877\u001b[0m     params,\n\u001b[1;32m    878\u001b[0m     grads,\n\u001b[1;32m    879\u001b[0m     exp_avgs,\n\u001b[1;32m    880\u001b[0m     exp_avg_sqs,\n\u001b[1;32m    881\u001b[0m     max_exp_avg_sqs,\n\u001b[1;32m    882\u001b[0m     state_steps,\n\u001b[1;32m    883\u001b[0m     amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    884\u001b[0m     has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    885\u001b[0m     beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    886\u001b[0m     beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    887\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    888\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m    889\u001b[0m     eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    890\u001b[0m     maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    891\u001b[0m     capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m    892\u001b[0m     differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m    893\u001b[0m     grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[1;32m    894\u001b[0m     found_inf\u001b[38;5;241m=\u001b[39mfound_inf,\n\u001b[1;32m    895\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:478\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    476\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m--> 478\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(params[i]):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utils.util import get_output_folder, setup_logger\n",
    "from wolp_agent import WolpertingerAgent\n",
    "import os\n",
    "\n",
    "# Change the current working directory to the parent folder\n",
    "os.chdir('..')\n",
    "\n",
    "args.save_model_dir = get_output_folder('../output', args.env)\n",
    "\n",
    "challenge_dictionary = json.load(open('data/RAW_DATA_DIR/arc-prize-2024/arc-agi_training_challenges.json'))\n",
    "action_space_args = {\n",
    "        'num_experiments_filter': args.num_experiments_filter, \n",
    "        'filter_threshold': args.filter_threshold, \n",
    "        'num_experiments_similarity': args.num_experiments_similarity,\n",
    "        'load': args.load_action_embedding\n",
    "    }\n",
    "\n",
    "action_space = ARCActionSpace(args)\n",
    "env = ARC_Env(challenge_dictionary, action_space)\n",
    "continuous = None\n",
    "\n",
    "# discrete action for 1 dimension\n",
    "# TODO: change the nb_states to the shape of the grid\n",
    "nb_states = 1805  # 60 x 30 grid ravels to 1800 + 4 for the dimensions of the grid + 1 for cls embedding\n",
    "nb_actions = 20  # the dimension of actions, usually it is 1. Depend on the environment.\n",
    "continuous = False\n",
    "\n",
    "if args.seed > 0:\n",
    "    np.random.seed(args.seed)\n",
    "    env.seed(args.seed)\n",
    "\n",
    "agent_args = {\n",
    "    'nb_states': nb_states,\n",
    "    'nb_actions': nb_actions,\n",
    "    'args': args,\n",
    "    'k': args.k_neighbors,\n",
    "    'action_space': action_space\n",
    "}\n",
    "\n",
    "agent = WolpertingerAgent(**agent_args)\n",
    "\n",
    "if args.load:\n",
    "    agent.load_weights(args.load_model_dir)\n",
    "\n",
    "if args.gpu_ids[0] >= 0 and args.gpu_nums > 0 and torch.cuda.is_available():\n",
    "    agent.cuda_convert()\n",
    "\n",
    "# set logger, log args here\n",
    "log = {}\n",
    "if args.mode == 'train':\n",
    "    setup_logger('RS_log', r'{}/RS_train_log'.format(args.save_model_dir))\n",
    "elif args.mode == 'test':\n",
    "    setup_logger('RS_log', r'{}/RS_test_log'.format(args.save_model_dir))\n",
    "else:\n",
    "    raise RuntimeError('undefined mode {}'.format(args.mode))\n",
    "\n",
    "log['RS_log'] = logging.getLogger('RS_log')\n",
    "d_args = vars(args)\n",
    "d_args['max_actions'] = args.max_actions\n",
    "\n",
    "for key in agent_args.keys():\n",
    "    if key == 'args':\n",
    "        continue\n",
    "    d_args[key] = agent_args[key]\n",
    "for k in d_args.keys():\n",
    "    log['RS_log'].info('{0}: {1}'.format(k, d_args[k]))\n",
    "\n",
    "if args.mode == 'train':\n",
    "    print('Training')\n",
    "\n",
    "    train_args = {\n",
    "        'continuous': continuous,\n",
    "        'env': env,\n",
    "        'agent': agent,\n",
    "        'max_episode': args.max_episode,\n",
    "        'max_actions': args.max_actions,\n",
    "        'warmup': args.warmup,\n",
    "        'save_model_dir': args.save_model_dir,\n",
    "        'max_episode_length': args.max_episode_length,\n",
    "        'logger': log['RS_log'],\n",
    "        'save_per_epochs': args.save_per_epochs\n",
    "    }\n",
    "\n",
    "    train(**train_args)\n",
    "\n",
    "elif args.mode == 'test':\n",
    "\n",
    "    test_args = {\n",
    "        'env': env,\n",
    "        'agent': agent,\n",
    "        'model_path': args.load_model_dir,\n",
    "        'test_episode': args.test_episode,\n",
    "        'max_episode_length': args.max_episode_length,\n",
    "        'logger': log['RS_log'],\n",
    "    }\n",
    "\n",
    "    test(**test_args)\n",
    "\n",
    "else:\n",
    "    raise RuntimeError('undefined mode {}'.format(args.mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_challenge_dict = json.load(open('../data/RAW_DATA_DIR/arc-prize-2024/arc-agi_training_challenges.json'))\n",
    "training_solutions_dict = json.load(open('../data/RAW_DATA_DIR/arc-prize-2024/arc-agi_training_solutions.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difficult problems\n",
    "- a64e4611\n",
    "- cbded52d\n",
    "- 508bd3b6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Selections and Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#\\xa0import the display_challenge function\\nfrom dsl.utilities.plot import display_challenge, plot_grid\\n\\n# find the first challenge and solution\\nchallenge_key = '1f85a75f'\\nchallenge_key = random_keys[n]\\nfirst_challenge = training_challenge_dict[challenge_key]\\nfirst_solution = training_solutions_dict[challenge_key]\\n\\nprint(f'Challenge key: {challenge_key}')\\n\\n#\\xa0display the challenge\\ndisplay_challenge(challenge_key)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# import the display_challenge function\n",
    "from dsl.utilities.plot import display_challenge, plot_grid\n",
    "\n",
    "# find the first challenge and solution\n",
    "challenge_key = '1f85a75f'\n",
    "challenge_key = random_keys[n]\n",
    "first_challenge = training_challenge_dict[challenge_key]\n",
    "first_solution = training_solutions_dict[challenge_key]\n",
    "\n",
    "print(f'Challenge key: {challenge_key}')\n",
    "\n",
    "# display the challenge\n",
    "display_challenge(challenge_key)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAFICAYAAAAyFGczAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEY0lEQVR4nO3WsWkDURBFUa/ZyIU4daDAudtTGUrU5bgA+8LCIr4Q58QTvOgy28zMGwB/vK8eAPCsBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEPbDlz/fD5wBr2e73FZPIMz189CdDxIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABwr56AOd9XT9WT+A/99UDOMsHCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAHCfvRwu9weuYMz7qsHwGvyQQIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAsM3MrB4B8Ix8kABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAA4ReyLxB4yQnnZQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dsl.utilities.plot import plot_grid \n",
    "arr2 = np.array([\n",
    "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 0, 2, 2],\n",
    "       [0, 0, 1, 1, 1, 1, 1, 0, 2, 2],\n",
    "       [0, 0, 0, 1, 1, 1, 0, 0, 2, 2],\n",
    "       [0, 0, 0, 1, 1, 1, 1, 1, 2, 2],\n",
    "       [0, 0, 0, 1, 0, 0, 1, 1, 2, 2],\n",
    "       [0, 0, 1, 1, 1, 1, 1, 0, 2, 2],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "arr = np.array([\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 4, 8, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 9, 4, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 2, 1, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 1, 2, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "])\n",
    "\n",
    "arr = np.array([\n",
    "              [2, 2, 1],\n",
    "              [2, 3, 1],\n",
    "              [1, 1, 1],\n",
    "              ])\n",
    "\n",
    "# plot the array as an image\n",
    "plot_grid(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular color: 1\n",
      "Least popular color: 3\n",
      "Second most popular color: 2\n",
      "Color of second biggest shape: 2\n"
     ]
    },
    {
     "ename": "DeprecationWarning",
     "evalue": "This method is deprecated. Use rank_largest_shape_color_nodiag instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDeprecationWarning\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m color_of_second_biggest_shape \u001b[38;5;241m=\u001b[39m colsel\u001b[38;5;241m.\u001b[39mrank_largest_shape_color_nodiag(arr, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColor of second biggest shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolor_of_second_biggest_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m color_of_second_biggest_shape \u001b[38;5;241m=\u001b[39m colsel\u001b[38;5;241m.\u001b[39mrank_largest_shape_color_diag(arr, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColor of second biggest shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolor_of_second_biggest_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Python/Personale/ARC with outputs/ARC/src/dsl/color_select.py:149\u001b[0m, in \u001b[0;36mColorSelector.rank_largest_shape_color_diag\u001b[0;34m(self, grid, rank)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrank_largest_shape_color_diag\u001b[39m(\u001b[38;5;28mself\u001b[39m, grid: np\u001b[38;5;241m.\u001b[39mndarray, rank: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    137\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    Return the color of the rank-th largest connected shape in the grid (considering diagonal connectivity).\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        DeprecationWarning: Always raised since this method is deprecated.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis method is deprecated. Use rank_largest_shape_color_nodiag instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# Deprecated implementation (kept for reference):\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     unique_colors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(grid)\n",
      "\u001b[0;31mDeprecationWarning\u001b[0m: This method is deprecated. Use rank_largest_shape_color_nodiag instead."
     ]
    }
   ],
   "source": [
    "from dsl.color_select import ColorSelector\n",
    "\n",
    "colsel = ColorSelector()\n",
    "\n",
    "popular_color = colsel.mostcolor(arr)\n",
    "print(f'Most popular color: {popular_color}')\n",
    "least_popular_color = colsel.leastcolor(arr)\n",
    "print(f'Least popular color: {least_popular_color}')\n",
    "\n",
    "second_most_popular_color = colsel.rankcolor(arr, 1)\n",
    "print(f'Second most popular color: {second_most_popular_color}')\n",
    "\n",
    "color_of_second_biggest_shape = colsel.rank_largest_shape_color_nodiag(arr, 1)\n",
    "print(f'Color of second biggest shape: {color_of_second_biggest_shape}')\n",
    "\n",
    "color_of_second_biggest_shape = colsel.rank_largest_shape_color_diag(arr, 1)\n",
    "print(f'Color of second biggest shape: {color_of_second_biggest_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by color\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting colored rectange combinations\n"
     ]
    },
    {
     "ename": "Warning",
     "evalue": "Color 0 not found in the grid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWarning\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m plot_selection(selection)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSelecting colored rectange combinations\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m selection3 \u001b[38;5;241m=\u001b[39m sel\u001b[38;5;241m.\u001b[39mselect_connected_shapes(arr, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     13\u001b[0m plot_selection(selection3)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSelecting cells adjacent to color\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Python/Personale/ARC with outputs/ARC/src/dsl/select.py:121\u001b[0m, in \u001b[0;36mSelector.select_connected_shapes\u001b[0;34m(self, grid, color)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_connected_shapes\u001b[39m(\u001b[38;5;28mself\u001b[39m, grid: np\u001b[38;5;241m.\u001b[39mndarray, color: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    Select connected shapes (4-connectivity) in the grid corresponding to the specified color.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m        np.ndarray: A 3D boolean array where each layer represents a connected component.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     color_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_color(grid, color)\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(color_mask) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mexpand_dims(np\u001b[38;5;241m.\u001b[39mzeros_like(grid), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Python/Personale/ARC with outputs/ARC/src/dsl/select.py:56\u001b[0m, in \u001b[0;36mSelector.select_color\u001b[0;34m(self, grid, color)\u001b[0m\n\u001b[1;32m     53\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(mask, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_rows, n_cols))\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(mask) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mWarning\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in the grid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mask\n",
      "\u001b[0;31mWarning\u001b[0m: Color 0 not found in the grid"
     ]
    }
   ],
   "source": [
    "from dsl.select import Selector\n",
    "from dsl.utilities.plot import plot_selection\n",
    "from skimage.segmentation import find_boundaries\n",
    "\n",
    "sel = Selector()\n",
    "\n",
    "print('Selecting by color')\n",
    "selection = sel.select_color(arr, 1)\n",
    "plot_selection(selection)\n",
    "\n",
    "print('Selecting colored rectange combinations')\n",
    "selection3 = sel.select_connected_shapes(arr, 0)\n",
    "plot_selection(selection3)\n",
    "\n",
    "print('Selecting cells adjacent to color')\n",
    "selection4 = sel.select_connected_shapes(arr, 1)\n",
    "plot_selection(selection4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Reinforcement learning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Creating the action space\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'ColorSelector' has no attribute 'max_embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m sel \u001b[38;5;241m=\u001b[39m Selector\n\u001b[1;32m      6\u001b[0m trn \u001b[38;5;241m=\u001b[39m Transformer\n\u001b[0;32m----> 8\u001b[0m action_space \u001b[38;5;241m=\u001b[39m ARCActionSpace(ColorSelector, Selector, Transformer)\n\u001b[1;32m     11\u001b[0m proto_action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m])\n\u001b[1;32m     12\u001b[0m distances, indices, actions \u001b[38;5;241m=\u001b[39m action_space\u001b[38;5;241m.\u001b[39msearch_point(proto_action, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Python/Personale/ARC with outputs/ARC/src/action_space.py:85\u001b[0m, in \u001b[0;36mARCActionSpace.__init__\u001b[0;34m(self, args, ColorSelector, Selector, Transformer)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Maximum and minimum embedding values (used for scaling)\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_embedding \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mmax_embedding\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_embedding \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mmin_embedding\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Weight used when uniformising the key density\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'ColorSelector' has no attribute 'max_embedding'"
     ]
    }
   ],
   "source": [
    "from action_space import ARCActionSpace\n",
    "from dsl.transform import Transformer\n",
    "from dsl.utilities.plot import plot_grid_3d\n",
    "colsel = ColorSelector\n",
    "sel = Selector\n",
    "trn = Transformer\n",
    "\n",
    "action_space = ARCActionSpace(ColorSelector, Selector, Transformer)\n",
    "\n",
    "\n",
    "proto_action = np.array([0.5, 0.5, 0.5])\n",
    "distances, indices, actions = action_space.search_point(proto_action, k=100)\n",
    "print('Closest actions:', actions[:5])\n",
    "print(actions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'action_space' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menviroment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ARC_Env\n\u001b[0;32m----> 3\u001b[0m env \u001b[38;5;241m=\u001b[39m ARC_Env(training_challenge_dict, action_space\u001b[38;5;241m=\u001b[39maction_space, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'action_space' is not defined"
     ]
    }
   ],
   "source": [
    "from enviroment import ARC_Env\n",
    "\n",
    "env = ARC_Env(training_challenge_dict, action_space=action_space, seed=0)\n",
    "seed = np.random.seed(1)\n",
    "random.seed(0)\n",
    "env.reset()\n",
    "\n",
    "i = 0\n",
    "while i<10000:\n",
    "    i += 1\n",
    "    action = random.choice(action_space.space)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    if i % 1000 == 0:\n",
    "        print(f'Step: {i}')\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def enlarge(grid, selection, radius):\n",
    "    \"\"\"\n",
    "    Enlarges the selected shape in the grid by a given radius, adding rows and columns of zeros between existing rows and columns.\n",
    "    \n",
    "    Args:\n",
    "        grid (np.ndarray): The original input grid\n",
    "        selection (np.ndarray): A binary mask indicating the shape (same shape as grid)\n",
    "        radius (int): Number of cells to expand outward\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: A new grid with the enlarged shape\n",
    "    #TODO: In the DRL environment radius will probably have to be an iterable for low numbers (likely between 1 and 3)\n",
    "    \"\"\"\n",
    "    # Ensure grid and selection are the same shape\n",
    "    assert grid.shape == selection.shape, \"Grid and each selection layer must have the same shape.\"\n",
    "    \n",
    "    rows, cols = grid.shape\n",
    "    # Create a larger grid with interstitial spaces\n",
    "    new_rows = rows * 2 - 1\n",
    "    new_cols = cols * 2 - 1\n",
    "    \n",
    "    # Add padding for the expansion\n",
    "    pad_rows = radius\n",
    "    pad_cols = radius\n",
    "    total_rows = new_rows + 2 * pad_rows\n",
    "    total_cols = new_cols + 2 * pad_cols\n",
    "    \n",
    "    # Create padded grid with zeros\n",
    "    padded_grid = np.zeros((total_rows, total_cols), dtype=grid.dtype)\n",
    "    padded_selection = np.zeros((total_rows, total_cols), dtype=selection.dtype)\n",
    "    \n",
    "    \n",
    "    # Fill original positions (accounting for padding offset)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if selection[i, j] == 1 and grid[i, j] == 1:\n",
    "                padded_grid[pad_rows + i*2, pad_cols + j*2] = 1\n",
    "                padded_selection[pad_rows + i*2, pad_cols + j*2] = 1\n",
    "    \n",
    "    # Find all non-zero elements in the grid (enlargement origins)\n",
    "    enlargement_origins = np.argwhere(padded_grid != 0)\n",
    "\n",
    "    # Iterate over each origin\n",
    "    for origin in enlargement_origins:\n",
    "        row, col = origin\n",
    "\n",
    "        # Vertical (upwards)\n",
    "        for r in range(1, radius + 1):\n",
    "            if row - r >= 0:  # Ensure we don't go out of bounds\n",
    "                padded_grid[row - r, col] = 1\n",
    "\n",
    "        # Horizontal (rightwards)\n",
    "        for c in range(1, radius + 1):\n",
    "            if col + c < padded_grid.shape[1]:  # Ensure we don't go out of bounds\n",
    "                padded_grid[row, col + c] = 1\n",
    "\n",
    "        # Diagonal (right-up)\n",
    "        for d in range(1, radius + 1):\n",
    "            if row - d >= 0 and col + d < padded_grid.shape[1]:  # Ensure we don't go out of bounds\n",
    "                padded_grid[row - d, col + d] = 1\n",
    "\n",
    "    return padded_grid\n",
    "\n",
    "\n",
    "# Test the function\n",
    "grid = np.array([\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0],\n",
    "])\n",
    "\n",
    "selection = np.array([\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0],\n",
    "])\n",
    "\n",
    "# Enlarge the selection with a radius of 1 and include diagonal neighbors\n",
    "result = enlarge(grid, selection, radius=1)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nOriginal Grid:\")\n",
    "print(grid)\n",
    "print(\"\\nEnlarged Grid:\")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_paths(x, y, last_move=None, consecutive=0, memo={}):\n",
    "    # Base case: reached destination\n",
    "    if x == 7 and y == 4:\n",
    "        return 1\n",
    "    # Base case: out of bounds\n",
    "    if x > 7 or y > 4:\n",
    "        return 0\n",
    "    # Memoization key\n",
    "    key = (x, y, last_move, consecutive)\n",
    "    if key in memo:\n",
    "        return memo[key]\n",
    "    \n",
    "    # Recursive case\n",
    "    ways = 0\n",
    "    # Move right if not violating the consecutive constraint\n",
    "    if last_move != 'R' or consecutive < 2:\n",
    "        ways += count_paths(x + 1, y, 'R', consecutive + 1 if last_move == 'R' else 1, memo)\n",
    "    # Move up if not violating the consecutive constraint\n",
    "    if last_move != 'U' or consecutive < 2:\n",
    "        ways += count_paths(x, y + 1, 'U', consecutive + 1 if last_move == 'U' else 1, memo)\n",
    "    \n",
    "    memo[key] = ways\n",
    "    return ways\n",
    "\n",
    "# Compute the number of ways\n",
    "result = count_paths(0, 0)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.array([\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0],\n",
    "])\n",
    "\n",
    "grid = np.expand_dims(grid, axis=0)\n",
    "print(grid.shape)\n",
    "\n",
    "def grid_to_tokens(grid):\n",
    "    \"\"\"\n",
    "    Converts a grid to a list of tokens.\n",
    "    \n",
    "    Args:\n",
    "        grid (np.ndarray): The input grid\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of tokens\n",
    "    \"\"\"\n",
    "    tokens = np.zeros(grid.size +2, dtype=np.float32)\n",
    "    d, nrows, ncols = grid.shape\n",
    "    tokens[0] = nrows\n",
    "    tokens[1] = ncols\n",
    "    tokens[2:] = grid.flatten()\n",
    "    return tokens\n",
    "\n",
    "tokens = grid_to_tokens(grid)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def downscale(grid, scale_factor, aggregation_fn=np.max):\n",
    "    \"\"\"\n",
    "    Downscales a grid by a given scale factor using a specified aggregation function.\n",
    "    \n",
    "    Args:\n",
    "        grid (np.ndarray): The input grid to downscale.\n",
    "        scale_factor (int): The factor by which to reduce the grid's size.\n",
    "        aggregation_fn (callable): The function to aggregate values in each block (default: np.max).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: The downscaled grid.\n",
    "    \"\"\"\n",
    "    assert grid.shape[0] % scale_factor == 0 and grid.shape[1] % scale_factor == 0, \\\n",
    "        \"Grid dimensions must be divisible by scale_factor.\"\n",
    "    \n",
    "    rows, cols = grid.shape\n",
    "    new_rows = rows // scale_factor\n",
    "    new_cols = cols // scale_factor\n",
    "\n",
    "    # Create the downscaled grid\n",
    "    downscaled_grid = np.zeros((new_rows, new_cols), dtype=grid.dtype)\n",
    "\n",
    "    # Iterate over blocks and apply aggregation function\n",
    "    for i in range(new_rows):\n",
    "        for j in range(new_cols):\n",
    "            block = grid[\n",
    "                i * scale_factor:(i + 1) * scale_factor,\n",
    "                j * scale_factor:(j + 1) * scale_factor\n",
    "            ]\n",
    "            downscaled_grid[i, j] = aggregation_fn(block)\n",
    "\n",
    "    return downscaled_grid\n",
    "\n",
    "# Test the function\n",
    "grid = np.array([\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 0, 0],\n",
    "    [1, 1, 1, 1, 0, 0],\n",
    "    [1, 1, 1, 1, 0, 0],\n",
    "    [1, 1, 1, 1, 0, 0]\n",
    "])\n",
    "\n",
    "selection = np.array([\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0]\n",
    "])\n",
    "\n",
    "# Enlarge the selection with a radius of 1\n",
    "result = downscale(grid, 3)\n",
    "\n",
    "print(\"\\nOriginal Grid:\")\n",
    "print(grid)\n",
    "print(\"\\nEnlarged Grid:\")\n",
    "print(result.astype(int))  # Convert to int for cleaner printing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dsl.select import Selector\n",
    "from dsl.transform import Transformer     \n",
    "from dsl.transform import Transformer\n",
    "from dsl.utilities.plot import plot_grid_3d, plot_selection, plot_grid\n",
    "\n",
    "\n",
    "arr = np.array([\n",
    "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 0, 2, 2],\n",
    "       [0, 0, 1, 1, 1, 1, 1, 0, 2, 2],\n",
    "       [0, 0, 0, 1, 1, 1, 0, 0, 2, 2],\n",
    "       [0, 0, 0, 1, 1, 1, 1, 1, 2, 2],\n",
    "       [0, 0, 0, 1, 0, 0, 1, 1, 2, 2],\n",
    "       [0, 0, 1, 1, 1, 1, 1, 0, 2, 2],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "# plot the array as an image\n",
    "plot_grid(arr)\n",
    "sel = Selector(arr.shape)\n",
    "trn = Transformer()\n",
    "print('Selecting cells adjacent to color')\n",
    "selection4 = sel.select_connected_shapes(arr, 1)\n",
    "plot_selection(selection4)\n",
    "print('Shift cells')\n",
    "transformed5 = trn.change_background_color(arr, selection4,7)\n",
    "plot_grid_3d(transformed5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dsl.select import Selector\n",
    "from dsl.transform import Transformer     \n",
    "from dsl.transform import Transformer\n",
    "from dsl.utilities.plot import plot_grid_3d, plot_selection, plot_grid\n",
    "\n",
    "\n",
    "arr1 = np.array([\n",
    "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 0, 2, 2],\n",
    "       [0, 0, 1, 1, 1, 1, 1, 0, 2, 2],\n",
    "       [0, 0, 0, 1, 1, 1, 0, 0, 2, 2],\n",
    "       [0, 0, 0, 1, 1, 1, 1, 1, 2, 2],\n",
    "       [0, 0, 0, 1, 0, 0, 1, 1, 2, 2],\n",
    "       [0, 0, 1, 1, 1, 1, 1, 0, 2, 2],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "arr2 = np.array([\n",
    "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 0, 2, 2],\n",
    "       [0, 0, 1, 1, 1, 1, 1, 0, 2, 2],\n",
    "       [0, 0, 0, 1, 1, 1, 0, 0, 2, 2],\n",
    "       [0, 0, 0, 1, 1, 1, 1, 1, 2, 2],\n",
    "       [0, 0, 0, 1, 0, 0, 1, 1, 2, 2],\n",
    "       [0, 0, 1, 1, 1, 1, 1, 0, 2, 2],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "# plot the array as an image\n",
    "plot_grid(arr1)\n",
    "sel1 = Selector(arr1.shape)\n",
    "sel2 = Selector(arr2.shape)\n",
    "trn = Transformer()\n",
    "print('Selecting cells adjacent to color')\n",
    "selection4 = sel1.select_connected_shapes(arr1, 1)\n",
    "selection5 = sel2.select_connected_shapes(arr2, 1)\n",
    "plot_selection(selection4)\n",
    "print('Vupscale')\n",
    "transformed5 = trn.vupscale(arr1, selection4, 2)\n",
    "plot_grid_3d(transformed5)\n",
    "print('Vectorized Vupscale')\n",
    "transformed6 = trn.vectorized_vupscale(arr2, selection4, 2)\n",
    "plot_grid_3d(transformed6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dsl.select import Selector\n",
    "from dsl.transform import Transformer     \n",
    "from dsl.transform import Transformer\n",
    "from dsl.utilities.plot import plot_grid_3d, plot_selection, plot_grid\n",
    "from dsl.utilities.transformation_utilities import center_of_mass\n",
    "\n",
    "\n",
    "arr1 = np.array([\n",
    "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "       [2, 0, 0, 0, 0, 0, 0, 0, 0, 2],\n",
    "       [2, 0, 1, 1, 1, 1, 0, 0, 0, 2],\n",
    "       [2, 0, 1, 0, 0, 1, 0, 0, 0, 2],\n",
    "       [2, 0, 1, 1, 1, 1, 0, 0, 0, 2],\n",
    "       [2, 0, 0, 0, 0, 0, 1, 1, 1, 2],\n",
    "       [2, 0, 0, 0, 0, 0, 1, 0, 1, 2],\n",
    "       [2, 0, 0, 0, 0, 0, 1, 1, 1, 2],\n",
    "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])\n",
    "\n",
    "arr2 = np.array([\n",
    "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "       [2, 0, 0, 0, 0, 0, 0, 0, 0, 2],\n",
    "       [2, 0, 1, 1, 1, 1, 0, 0, 0, 2],\n",
    "       [2, 0, 1, 0, 0, 1, 0, 0, 0, 2],\n",
    "       [2, 0, 1, 1, 1, 1, 0, 0, 0, 2],\n",
    "       [2, 0, 0, 0, 0, 0, 1, 1, 1, 2],\n",
    "       [2, 0, 0, 0, 0, 0, 1, 0, 1, 2],\n",
    "       [2, 0, 0, 0, 0, 0, 1, 1, 1, 2],\n",
    "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])\n",
    "\n",
    "# plot the array as an image\n",
    "plot_grid(arr1)\n",
    "sel1 = Selector(arr1.shape)\n",
    "sel2 = Selector(arr2.shape)\n",
    "trn = Transformer()\n",
    "print('Selecting cells adjacent to color')\n",
    "selection4 = sel1.select_connected_shapes(arr1, 1)\n",
    "selection5 = sel2.select_connected_shapes(arr2, 1)\n",
    "plot_selection(selection4)\n",
    "print('Vupscale')\n",
    "transformed5 = trn.vupscale(arr1, selection4, 2)\n",
    "plot_grid_3d(transformed5)\n",
    "print('Vectorized Vupscale')\n",
    "transformed6 = trn.vectorized_vupscale(arr2, selection4, 2)\n",
    "plot_grid_3d(transformed6)\n",
    "\n",
    "\n",
    "\n",
    "CoM1 = center_of_mass(selection4[0])\n",
    "CoM2 = center_of_mass(selection4[1])\n",
    "print(f'Center of mass of shape 0: {CoM1}')\n",
    "print(f'Center of mass of shape 1: {CoM2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def maximum_overlap_regions_old(array1, array2):\n",
    "        \"\"\"\n",
    "        Vectorized calculation of maximum overlap between two 2D arrays.\n",
    "        \"\"\"\n",
    "        shape1 = array1.shape\n",
    "        shape2 = array2.shape\n",
    "        \n",
    "        # Calculate possible positions for sliding array2 over array1\n",
    "        offsets_i = np.arange(-shape2[0] + 1, shape1[0])\n",
    "        offsets_j = np.arange(-shape2[1] + 1, shape1[1])\n",
    "        \n",
    "        # Create grids for all possible offsets\n",
    "        grid_i, grid_j = np.meshgrid(offsets_i, offsets_j, indexing='ij')\n",
    "        \n",
    "        # Calculate the valid overlap regions for each position\n",
    "        row_start1 = np.maximum(0, grid_i)\n",
    "        row_end1 = np.minimum(shape1[0], grid_i + shape2[0])\n",
    "        col_start1 = np.maximum(0, grid_j)\n",
    "        col_end1 = np.minimum(shape1[1], grid_j + shape2[1])\n",
    "        \n",
    "        row_start2 = np.maximum(0, -grid_i)\n",
    "        row_end2 = row_start2 + (row_end1 - row_start1)\n",
    "        col_start2 = np.maximum(0, -grid_j)\n",
    "        col_end2 = col_start2 + (col_end1 - col_start1)\n",
    "        \n",
    "        # Calculate overlap scores for all positions\n",
    "        max_overlap_score = 0\n",
    "        best_overlap1 = None\n",
    "        best_overlap2 = None\n",
    "        \n",
    "        for idx in np.ndindex(grid_i.shape):\n",
    "            r1s, r1e = row_start1[idx], row_end1[idx]\n",
    "            c1s, c1e = col_start1[idx], col_end1[idx]\n",
    "            r2s, r2e = row_start2[idx], row_end2[idx]\n",
    "            c2s, c2e = col_start2[idx], col_end2[idx]\n",
    "            \n",
    "            region1 = array1[r1s:r1e, c1s:c1e]\n",
    "            region2 = array2[r2s:r2e, c2s:c2e]\n",
    "            \n",
    "            overlap_score = np.sum(region1 == region2)\n",
    "            \n",
    "            if overlap_score > max_overlap_score:\n",
    "                max_overlap_score = overlap_score\n",
    "                best_overlap1 = (slice(r1s, r1e), slice(c1s, c1e))\n",
    "                best_overlap2 = (slice(r2s, r2e), slice(c2s, c2e))\n",
    "        \n",
    "        return best_overlap1, best_overlap2\n",
    "# Functions to test\n",
    "def test_overlap_functions():\n",
    "    def generate_random_grids(max_size=30):\n",
    "        size1 = np.random.randint(2, max_size+1, size=2)  # Random size for grid 1\n",
    "        size2 = np.random.randint(2, max_size+1, size=2)  # Random size for grid 2\n",
    "        grid1 = np.random.randint(0, 5, size=size1)       # Random grid 1 with values 0-4\n",
    "        grid2 = np.random.randint(0, 5, size=size2)       # Random grid 2 with values 0-4\n",
    "        return grid1, grid2\n",
    "\n",
    "    num_tests = 10\n",
    "    max_size = 5\n",
    "\n",
    "    old_times = []\n",
    "    new_times = []\n",
    "\n",
    "    for test_idx in range(num_tests):\n",
    "        grid1, grid2 = generate_random_grids(max_size)\n",
    "\n",
    "        # Test old function\n",
    "        start_time = time.time()\n",
    "        old_result1, old_result2 = maximum_overlap_regions_old(grid1, grid2)\n",
    "        old_times.append(time.time() - start_time)\n",
    "\n",
    "        # Test new function\n",
    "        start_time = time.time()\n",
    "        new_result1, new_result2 = maximum_overlap_regions(grid1, grid2)\n",
    "        new_times.append(time.time() - start_time)\n",
    "\n",
    "        # Verify that the results match\n",
    "        if old_result1 != new_result1 or old_result2 != new_result2:\n",
    "            print(f\"Mismatch on test {test_idx}:\")\n",
    "            print(\"Grid1:\")\n",
    "            print(grid1)\n",
    "            print(\"Grid2:\")\n",
    "            print(grid2)\n",
    "            print(\"Old function results:\")\n",
    "            print(old_result1, old_result2)\n",
    "            print(grid1[old_result1])\n",
    "            print(grid2[old_result2])\n",
    "            print('Overlap:', np.sum(grid1[old_result1] == grid2[old_result2]))\n",
    "            print('')\n",
    "            print(\"New function results:\")\n",
    "            print(new_result1, new_result2)\n",
    "            print(grid1[new_result1])\n",
    "            print(grid2[new_result2])\n",
    "            print('Overlap:', np.sum(grid1[new_result1] == grid2[new_result2]))\n",
    "            raise AssertionError(f\"Mismatch in results on test {test_idx}\")\n",
    "\n",
    "        print(f\"Test {test_idx + 1}/{num_tests}: PASSED\")\n",
    "\n",
    "    print(f\"\\nAverage time for old function: {np.mean(old_times):.6f} seconds\")\n",
    "    print(f\"Average time for new function: {np.mean(new_times):.6f} seconds\")\n",
    "\n",
    "# Run the tests\n",
    "test_overlap_functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import inspect\n",
    "import torch\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from dsl.utilities.plot import plot_grid, plot_grid_3d, plot_selection, display_challenge\n",
    "from action_space import ARCActionSpace\n",
    "from dsl.transform import Transformer\n",
    "from enviroment import ARC_Env\n",
    "\n",
    "from cleaner import cleaner\n",
    "\n",
    "cleaner()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
